https://github.com/user-attachments/assets/c6bb8163-9605-41d2-a22c-5babed00ade9

Marker-Based Human-Following Robot Using YOLOv8 for Assistive Load Transportation
Developed an autonomous human-following mobile robot that tracks a user wearing a red circular marker to assist with indoor load carrying in healthcare, logistics, and public environments. The system is built on a Raspberry Pi 5 with a 720p RGB camera, differential-drive base, and dual IR sensors, enabling real-time detection and safe navigation on low-cost hardware.

Created and annotated a 4,500-image dataset of the marker under different distances, angles, lighting conditions, and occlusions, and trained a YOLOv8n model optimized with NCNN for embedded deployment. Implemented vision-based steering and distance control using bounding-box geometry, removing the need for external range sensors and achieving accurate, robust following performance in crowded indoor trials.
